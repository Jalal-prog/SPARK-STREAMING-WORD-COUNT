// After starting the scala-spark shell ($ spark-shell)
// Below is the API for word count in SPARK STREAMING CONTEXT through loading a data file from localhost port-9999 and saving into HDFS path.

scala> //cutting off 'scala>' for the below codes for easy copy.

import org.apache.spark.{SparkContext, SparkConf}
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.storage.StorageLevel
import org.apache.log4j.{Level, Logger}
Logger.getRootLogger.setLevel(Level.WARN)
val ssc = new StreamingContext(sc, Seconds(5))
val lines = ssc.textFileStream("localhost", 9999)
val words = lines flatMap {line => line.split(" ")}
val wordCounts = words.countByValue()
wordCounts.saveAsTextFiles("hdfs://localhost:8020/PATH")
wordCounts.print()
ssc.start() //This will start the spark streaming

//Open another console, just input some data as below

$ nc -lk 9999
<put some words here>
// You can see the output from Spark Streaming console.

// make a note of the time of the result displayed to open that particular file into the hdfs output path
// To stop the SPARK STREAMING console pres "Ctrl+C"
// Go to the HDFS path ("hdfs://localhost:8020/PATH") to check the result.

// Similarly we can change the hdfs path to the local path to save the output. 

